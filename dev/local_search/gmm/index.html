<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GMM · UnsupervisedClustering</title><meta name="title" content="GMM · UnsupervisedClustering"/><meta property="og:title" content="GMM · UnsupervisedClustering"/><meta property="twitter:title" content="GMM · UnsupervisedClustering"/><meta name="description" content="Documentation for UnsupervisedClustering."/><meta property="og:description" content="Documentation for UnsupervisedClustering."/><meta property="twitter:description" content="Documentation for UnsupervisedClustering."/><meta property="og:url" content="https://raphasampaio.github.io/UnsupervisedClustering.jl/local_search/gmm/"/><meta property="twitter:url" content="https://raphasampaio.github.io/UnsupervisedClustering.jl/local_search/gmm/"/><link rel="canonical" href="https://raphasampaio.github.io/UnsupervisedClustering.jl/local_search/gmm/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="UnsupervisedClustering logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">UnsupervisedClustering</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><span class="tocitem">Local Search</span><ul><li><a class="tocitem" href="../kmeans/">k-means</a></li><li><a class="tocitem" href="../kmeanspp/">k-means++</a></li><li><a class="tocitem" href="../kmedoids/">k-medoids</a></li><li class="is-active"><a class="tocitem" href>GMM</a><ul class="internal"><li><a class="tocitem" href="#Algorithm-Overview"><span>Algorithm Overview</span></a></li><li><a class="tocitem" href="#Basic-Usage"><span>Basic Usage</span></a></li><li><a class="tocitem" href="#Covariance-Matrix-Estimation"><span>Covariance Matrix Estimation</span></a></li><li><a class="tocitem" href="#Comparison-with-K-means"><span>Comparison with K-means</span></a></li><li><a class="tocitem" href="#Configuration-Options"><span>Configuration Options</span></a></li><li><a class="tocitem" href="#Probabilistic-Clustering"><span>Probabilistic Clustering</span></a></li><li><a class="tocitem" href="#Advanced-Example-with-Model-Selection"><span>Advanced Example with Model Selection</span></a></li><li><a class="tocitem" href="#Integration-with-Other-Algorithms"><span>Integration with Other Algorithms</span></a></li><li><a class="tocitem" href="#Handling-High-Dimensional-Data"><span>Handling High-Dimensional Data</span></a></li><li><a class="tocitem" href="#Performance-Comparison"><span>Performance Comparison</span></a></li><li><a class="tocitem" href="#When-to-Use-GMM"><span>When to Use GMM</span></a></li><li><a class="tocitem" href="#Limitations"><span>Limitations</span></a></li><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li></ul></li><li><span class="tocitem">Metaheuristic</span><ul><li><a class="tocitem" href="../../metaheuristic/multi_start/">Multi-Start</a></li><li><a class="tocitem" href="../../metaheuristic/random_swap/">Random Swap</a></li><li><a class="tocitem" href="../../metaheuristic/genetic_algorithm/">Genetic Algorithm</a></li></ul></li><li><span class="tocitem">Ensemble</span><ul><li><a class="tocitem" href="../../ensemble/chain/">Clustering Chain</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Local Search</a></li><li class="is-active"><a href>GMM</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>GMM</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/main/docs/src/local_search/gmm.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Gaussian-Mixture-Models-(GMM)"><a class="docs-heading-anchor" href="#Gaussian-Mixture-Models-(GMM)">Gaussian Mixture Models (GMM)</a><a id="Gaussian-Mixture-Models-(GMM)-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-Mixture-Models-(GMM)" title="Permalink"></a></h1><p>Gaussian Mixture Models represent data as a mixture of Gaussian distributions, providing probabilistic cluster assignments and soft clustering capabilities. Unlike k-means, GMM can model elliptical clusters and provides uncertainty estimates.</p><h2 id="Algorithm-Overview"><a class="docs-heading-anchor" href="#Algorithm-Overview">Algorithm Overview</a><a id="Algorithm-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm-Overview" title="Permalink"></a></h2><p>GMM uses the Expectation-Maximization (EM) algorithm:</p><ol><li><strong>E-step</strong>: Calculate probabilities of each point belonging to each Gaussian component</li><li><strong>M-step</strong>: Update Gaussian parameters (means, covariances, mixing weights) based on probabilities</li><li><strong>Repeat</strong>: Continue until convergence of log-likelihood</li></ol><h2 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h2><pre><code class="language-julia hljs">using UnsupervisedClustering

# Generate sample data
data = rand(100, 2)
k = 3

# Create covariance estimator (required for GMM)
n, d = size(data)
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

# Create and run GMM
gmm = GMM(estimator = estimator)
result = fit(gmm, data, k)

println(&quot;Log-likelihood: $(result.objective)&quot;)
println(&quot;Converged: $(result.converged)&quot;)</code></pre><h2 id="Covariance-Matrix-Estimation"><a class="docs-heading-anchor" href="#Covariance-Matrix-Estimation">Covariance Matrix Estimation</a><a id="Covariance-Matrix-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-Matrix-Estimation" title="Permalink"></a></h2><p>GMM requires a covariance estimator to handle numerical stability:</p><pre><code class="language-julia hljs"># Different estimator types
n, d = size(data)

# Empirical covariance (default)
emp_estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

# For integration with RegularizedCovarianceMatrices.jl
# regularized_estimator = SomeRegularizedEstimator(n, d)

gmm_empirical = GMM(estimator = emp_estimator)
result = fit(gmm_empirical, data, k)</code></pre><h2 id="Comparison-with-K-means"><a class="docs-heading-anchor" href="#Comparison-with-K-means">Comparison with K-means</a><a id="Comparison-with-K-means-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison-with-K-means" title="Permalink"></a></h2><pre><code class="language-julia hljs">using UnsupervisedClustering, Random

# Create elliptical clusters (GMM should perform better)
Random.seed!(42)
cluster1 = [randn(50) randn(50) * 0.3] .+ [2, 2]   # Elongated cluster
cluster2 = [randn(50) * 0.3 randn(50)] .+ [-2, -2]  # Elongated cluster
cluster3 = randn(50, 2) .+ [0, 3]                   # Circular cluster
data = vcat(cluster1, cluster2, cluster3)

n, d = size(data)
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

# Compare algorithms
algorithms = [
    (&quot;K-means&quot;, Kmeans()),
    (&quot;GMM&quot;, GMM(estimator = estimator))
]

println(&quot;Algorithm Comparison on Elliptical Data:&quot;)
for (name, alg) in algorithms
    result = fit(alg, data, 3)
    println(&quot;$name: objective = $(round(result.objective, digits=3))&quot;)
end</code></pre><h2 id="Configuration-Options"><a class="docs-heading-anchor" href="#Configuration-Options">Configuration Options</a><a id="Configuration-Options-1"></a><a class="docs-heading-anchor-permalink" href="#Configuration-Options" title="Permalink"></a></h2><pre><code class="language-julia hljs"># Customize GMM parameters
n, d = size(data)
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

gmm = GMM(
    estimator = estimator,
    tolerance = 1e-6,           # Convergence threshold
    max_iterations = 1000,      # Maximum EM iterations
    verbose = false             # Print progress
)

result = fit(gmm, data, k)</code></pre><h2 id="Probabilistic-Clustering"><a class="docs-heading-anchor" href="#Probabilistic-Clustering">Probabilistic Clustering</a><a id="Probabilistic-Clustering-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-Clustering" title="Permalink"></a></h2><p>GMM provides soft cluster assignments (probabilities):</p><pre><code class="language-julia hljs"># Get clustering result
result = fit(GMM(estimator = estimator), data, 3)

# Hard assignments (like k-means)
hard_assignments = result.assignments

# For soft assignments, you would typically access the posterior probabilities
# This requires running the E-step separately or modifying the algorithm
println(&quot;Hard cluster assignments: $(hard_assignments[1:10])&quot;)</code></pre><h2 id="Advanced-Example-with-Model-Selection"><a class="docs-heading-anchor" href="#Advanced-Example-with-Model-Selection">Advanced Example with Model Selection</a><a id="Advanced-Example-with-Model-Selection-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Example-with-Model-Selection" title="Permalink"></a></h2><pre><code class="language-julia hljs">using UnsupervisedClustering, Random

# Create complex dataset
Random.seed!(42)
cluster1 = randn(40, 3) .+ [3, 3, 3]
cluster2 = randn(40, 3) .+ [-3, -3, -3]
cluster3 = randn(40, 3) .+ [3, -3, 0]
data = vcat(cluster1, cluster2, cluster3)

# Try different numbers of components
k_values = 2:6
log_likelihoods = Float64[]

n, d = size(data)
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

println(&quot;Model Selection for GMM:&quot;)
for k in k_values
    gmm = GMM(estimator = estimator, max_iterations = 200)
    result = fit(gmm, data, k)
    push!(log_likelihoods, result.objective)
    println(&quot;k=$k: log-likelihood = $(round(result.objective, digits=3))&quot;)
end

# Higher log-likelihood indicates better fit
best_k = k_values[argmax(log_likelihoods)]
println(&quot;Best k based on log-likelihood: $best_k&quot;)</code></pre><h2 id="Integration-with-Other-Algorithms"><a class="docs-heading-anchor" href="#Integration-with-Other-Algorithms">Integration with Other Algorithms</a><a id="Integration-with-Other-Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Integration-with-Other-Algorithms" title="Permalink"></a></h2><pre><code class="language-julia hljs"># Use GMM in algorithm chains
n, d = size(data)
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

# Initialize with k-means, refine with GMM
chain = ClusteringChain(
    Kmeans(max_iterations = 50),
    GMM(estimator = estimator, max_iterations = 100)
)

result_chain = fit(chain, data, 3)
println(&quot;Chained k-means → GMM: $(result_chain.objective)&quot;)

# Use GMM with metaheuristics
genetic_gmm = GeneticAlgorithm(
    local_search = GMM(estimator = estimator, max_iterations = 50),
    max_iterations = 50
)

result_genetic = fit(genetic_gmm, data, 3)
println(&quot;Genetic GMM: $(result_genetic.objective)&quot;)</code></pre><h2 id="Handling-High-Dimensional-Data"><a class="docs-heading-anchor" href="#Handling-High-Dimensional-Data">Handling High-Dimensional Data</a><a id="Handling-High-Dimensional-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Handling-High-Dimensional-Data" title="Permalink"></a></h2><pre><code class="language-julia hljs"># For high-dimensional data, consider regularization
high_dim_data = rand(100, 20)  # 20-dimensional data
n, d = size(high_dim_data)

# Use empirical estimator
estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)

# Reduce iterations for efficiency
gmm_hd = GMM(
    estimator = estimator,
    max_iterations = 100,
    tolerance = 1e-4
)

result = fit(gmm_hd, high_dim_data, 5)
println(&quot;High-dimensional GMM: $(result.objective)&quot;)</code></pre><h2 id="Performance-Comparison"><a class="docs-heading-anchor" href="#Performance-Comparison">Performance Comparison</a><a id="Performance-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Comparison" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Statistics

# Compare convergence behavior
objectives_gmm = Float64[]
objectives_kmeans = Float64[]

for trial in 1:10
    # K-means
    result_km = fit(Kmeans(), data, 3)
    push!(objectives_kmeans, result_km.objective)

    # GMM
    n, d = size(data)
    estimator = UnsupervisedClustering.EmpiricalCovarianceMatrix(n, d)
    result_gmm = fit(GMM(estimator = estimator), data, 3)
    push!(objectives_gmm, result_gmm.objective)
end

println(&quot;K-means objective statistics:&quot;)
println(&quot;  Mean: $(round(mean(objectives_kmeans), digits=3))&quot;)
println(&quot;  Std:  $(round(std(objectives_kmeans), digits=3))&quot;)

println(&quot;GMM log-likelihood statistics:&quot;)
println(&quot;  Mean: $(round(mean(objectives_gmm), digits=3))&quot;)
println(&quot;  Std:  $(round(std(objectives_gmm), digits=3))&quot;)</code></pre><h2 id="When-to-Use-GMM"><a class="docs-heading-anchor" href="#When-to-Use-GMM">When to Use GMM</a><a id="When-to-Use-GMM-1"></a><a class="docs-heading-anchor-permalink" href="#When-to-Use-GMM" title="Permalink"></a></h2><p>GMM is preferred when:</p><ul><li><strong>Probabilistic clusters</strong>: Need soft assignments or uncertainty estimates</li><li><strong>Non-spherical clusters</strong>: Data has elliptical or complex cluster shapes</li><li><strong>Overlapping clusters</strong>: Clusters have significant overlap</li><li><strong>Model-based approach</strong>: Want principled statistical foundation</li><li><strong>Density estimation</strong>: Need to model data distribution, not just clustering</li></ul><h2 id="Limitations"><a class="docs-heading-anchor" href="#Limitations">Limitations</a><a id="Limitations-1"></a><a class="docs-heading-anchor-permalink" href="#Limitations" title="Permalink"></a></h2><ul><li><strong>Computational cost</strong>: More expensive than k-means</li><li><strong>Covariance estimation</strong>: Requires careful handling in high dimensions</li><li><strong>Local optima</strong>: Can get stuck like other EM-based methods</li><li><strong>Model assumptions</strong>: Assumes Gaussian distributions</li></ul><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="UnsupervisedClustering.GMM" href="#UnsupervisedClustering.GMM"><code>UnsupervisedClustering.GMM</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GMM(
    estimator::CovarianceMatrixEstimator
    verbose::Bool = DEFAULT_VERBOSE
    rng::AbstractRNG = Random.GLOBAL_RNG
    tolerance::Float64 = DEFAULT_TOLERANCE
    max_iterations::Int = DEFAULT_MAX_ITERATIONS
    decompose_if_fails::Bool = true
)</code></pre><p>The GMM is a clustering algorithm that models the underlying data distribution as a mixture of Gaussian distributions.</p><p><strong>Fields</strong></p><ul><li><code>estimator</code>: represents the method or algorithm used to estimate the covariance matrices in the GMM. </li><li><code>verbose</code>: controls whether the algorithm should display additional information during execution.</li><li><code>rng</code>: represents the random number generator to be used by the algorithm.</li><li><code>tolerance</code>: represents the convergence criterion for the algorithm. It determines the maximum change allowed in the model&#39;s log-likelihood between consecutive iterations before considering convergence.</li><li><code>max_iterations</code>: represents the maximum number of iterations the algorithm will perform before stopping, even if convergence has not been reached.</li><li><code>decompose_if_fails</code>: determines whether the algorithm should attempt to decompose the covariance matrix of a component and fix its eigenvalues if the decomposition fails due to numerical issues.       </li></ul><p><strong>References</strong></p><ul><li>Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society: series B (methodological) 39.1 (1977): 1-22.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/26482d45027c17ac85eb5670da1a326c9836bb4b/src/local_search/gmm.jl#L1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="UnsupervisedClustering.GMMResult" href="#UnsupervisedClustering.GMMResult"><code>UnsupervisedClustering.GMMResult</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GMMResult(
    assignments::AbstractVector{&lt;:Integer}
    weights::AbstractVector{&lt;:Real}
    clusters::AbstractVector{&lt;:AbstractVector{&lt;:Real}}
    covariances::AbstractVector{&lt;:Symmetric{&lt;:Real}}
    objective::Real
    iterations::Integer
    elapsed::Real
    converged::Bool
    k::Integer
)</code></pre><p>GMMResult struct represents the result of the GMM clustering algorithm.</p><p><strong>Fields</strong></p><ul><li><code>assignments</code>: an integer vector that stores the cluster assignment for each data point.</li><li><code>weights</code>: a vector of floating-point numbers representing the weights associated with each cluster. The weight indicates the probability of a data point belonging to its respective cluster.</li><li><code>clusters</code>: a vector of floating-point vectors representing the cluster&#39;s centroid.</li><li><code>covariances</code>: a vector of symmetric matrices, where each matrix represents the covariance matrix of a cluster in the GMM model. The covariance matrix describes the shape and orientation of the data distribution within each cluster.</li><li><code>objective</code>: a floating-point number representing the objective function after running the algorithm. The objective function measures the quality of the clustering solution.</li><li><code>iterations</code>: an integer value indicating the number of iterations performed until the algorithm has converged or reached the maximum number of iterations</li><li><code>elapsed</code>: a floating-point number representing the time in seconds for the algorithm to complete.</li><li><code>converged</code>: indicates whether the algorithm has converged to a solution.</li><li><code>k</code>: the number of clusters.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/26482d45027c17ac85eb5670da1a326c9836bb4b/src/local_search/gmm.jl#L35-L60">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="UnsupervisedClustering.fit!-Tuple{GMM, AbstractMatrix{&lt;:Real}, UnsupervisedClustering.GMMResult}" href="#UnsupervisedClustering.fit!-Tuple{GMM, AbstractMatrix{&lt;:Real}, UnsupervisedClustering.GMMResult}"><code>UnsupervisedClustering.fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit!(
    gmm::GMM,
    data::AbstractMatrix{&lt;:Real},
    result::GMMResult
)</code></pre><p>The <code>fit!</code> function performs the GMM clustering algorithm on the given result as the initial point and updates the provided object with the clustering result.</p><p><strong>Parameters:</strong></p><ul><li><code>gmm</code>: an instance representing the clustering settings and parameters.</li><li><code>data</code>: a floating-point matrix, where each row represents a data point, and each column represents a feature.</li><li><code>result</code>: a result object that will be updated with the clustering result.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">n = 100
d = 2
k = 2

data = rand(n, d)

gmm = GMM(estimator = EmpiricalCovarianceMatrix(n, d))
result = GMMResult(n, [[1.0, 1.0], [2.0, 2.0]])
fit!(gmm, data, result)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/26482d45027c17ac85eb5670da1a326c9836bb4b/src/local_search/gmm.jl#L275-L302">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="UnsupervisedClustering.fit-Tuple{GMM, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Integer}}" href="#UnsupervisedClustering.fit-Tuple{GMM, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Integer}}"><code>UnsupervisedClustering.fit</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit(
    gmm::GMM,
    data::AbstractMatrix{&lt;:Real},
    initial_clusters::AbstractVector{&lt;:Integer}
)</code></pre><p>The <code>fit</code> function performs the GMM clustering algorithm on the given data points as the initial point and returns a result object representing the clustering result.</p><p><strong>Parameters:</strong></p><ul><li><code>kmeans</code>: an instance representing the clustering settings and parameters.</li><li><code>data</code>: a floating-point matrix, where each row represents a data point, and each column represents a feature.</li><li><code>initial_clusters</code>: an integer vector where each element is the initial data point for each cluster.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">n = 100
d = 2
k = 2

data = rand(n, d)

gmm = GMM(estimator = EmpiricalCovarianceMatrix(n, d))
result = fit(gmm, data, [4, 12])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/26482d45027c17ac85eb5670da1a326c9836bb4b/src/local_search/gmm.jl#L364-L390">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="UnsupervisedClustering.fit-Tuple{GMM, AbstractMatrix{&lt;:Real}, Integer}" href="#UnsupervisedClustering.fit-Tuple{GMM, AbstractMatrix{&lt;:Real}, Integer}"><code>UnsupervisedClustering.fit</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit(
    gmm::GMM,
    data::AbstractMatrix{&lt;:Real},
    k::Integer
)</code></pre><p>The <code>fit</code> function performs the GMM clustering algorithm and returns a result object representing the clustering result.</p><p><strong>Parameters:</strong></p><ul><li><code>gmm</code>: an instance representing the clustering settings and parameters.</li><li><code>data</code>: a floating-point matrix, where each row represents a data point, and each column represents a feature.</li><li><code>k</code>: an integer representing the number of clusters.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">n = 100
d = 2
k = 2

data = rand(n, d)

gmm = GMM(estimator = EmpiricalCovarianceMatrix(n, d))
result = fit(gmm, data, k)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/raphasampaio/UnsupervisedClustering.jl/blob/26482d45027c17ac85eb5670da1a326c9836bb4b/src/local_search/gmm.jl#L411-L437">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../kmedoids/">« k-medoids</a><a class="docs-footer-nextpage" href="../../metaheuristic/multi_start/">Multi-Start »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 27 September 2025 21:32">Saturday 27 September 2025</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
